{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4951650,"sourceType":"datasetVersion","datasetId":2871491}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nfrom glob import glob\n\nvideo_root = \"/kaggle/input/ravdess-emotional-speech-video/RAVDESS dataset\"\nsave_root = \"/kaggle/working/frames\"\nos.makedirs(save_root, exist_ok=True)\n\nvideo_paths = sorted(glob(os.path.join(video_root, \"**/*.mp4\"), recursive=True))\n\nfor video_path in video_paths:\n    file_name = os.path.basename(video_path).replace(\".mp4\", \"\")\n    save_dir = os.path.join(save_root, file_name)\n    os.makedirs(save_dir, exist_ok=True)\n\n    cap = cv2.VideoCapture(video_path)\n    ret, frame = cap.read()\n    if ret:\n        save_path = os.path.join(save_dir, \"frame_0000.jpg\")\n        cv2.imwrite(save_path, frame)\n    cap.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:19:36.438282Z","iopub.execute_input":"2025-07-23T18:19:36.438904Z","iopub.status.idle":"2025-07-23T18:21:38.327606Z","shell.execute_reply.started":"2025-07-23T18:19:36.438883Z","shell.execute_reply":"2025-07-23T18:21:38.326814Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\n\ndata = []\nemotion_map = {\n    1: \"neutral\",\n    2: \"calm\",\n    3: \"happy\",\n    4: \"sad\",\n    5: \"angry\",\n    6: \"fearful\",\n    7: \"disgust\",\n    8: \"surprised\"\n}\n\nframe_dirs = sorted(glob(os.path.join(save_root, \"*\")))\n\nfor frame_dir in frame_dirs:\n    folder_name = os.path.basename(frame_dir)\n    parts = folder_name.split(\"-\")\n\n    if len(parts) == 7:\n        emotion_code = int(parts[2])\n        intensity = int(parts[3])\n        statement = int(parts[4])\n        repetition = int(parts[5])\n        actor = int(parts[6])\n\n        label = emotion_map.get(emotion_code)\n        if label:\n            frame_path = os.path.join(frame_dir, \"frame_0000.jpg\")\n            data.append([frame_path, label, emotion_code, intensity, statement, repetition, actor])\n\ndf = pd.DataFrame(data, columns=[\n    \"frame_dir\", \"label\", \"emotion_code\", \"intensity\", \"statement\", \"repetition\", \"actor\"\n])\ndf.to_csv(\"/kaggle/working/ravdess_labels.csv\", index=False)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:21:38.328771Z","iopub.execute_input":"2025-07-23T18:21:38.329148Z","iopub.status.idle":"2025-07-23T18:21:38.368124Z","shell.execute_reply.started":"2025-07-23T18:21:38.329119Z","shell.execute_reply":"2025-07-23T18:21:38.367521Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                           frame_dir    label  emotion_code  \\\n0  /kaggle/working/frames/01-01-01-01-01-01-01/fr...  neutral             1   \n1  /kaggle/working/frames/01-01-01-01-01-01-02/fr...  neutral             1   \n2  /kaggle/working/frames/01-01-01-01-01-01-03/fr...  neutral             1   \n3  /kaggle/working/frames/01-01-01-01-01-01-04/fr...  neutral             1   \n4  /kaggle/working/frames/01-01-01-01-01-01-05/fr...  neutral             1   \n\n   intensity  statement  repetition  actor  \n0          1          1           1      1  \n1          1          1           1      2  \n2          1          1           1      3  \n3          1          1           1      4  \n4          1          1           1      5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame_dir</th>\n      <th>label</th>\n      <th>emotion_code</th>\n      <th>intensity</th>\n      <th>statement</th>\n      <th>repetition</th>\n      <th>actor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/frames/01-01-01-01-01-01-01/fr...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/frames/01-01-01-01-01-01-02/fr...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/frames/01-01-01-01-01-01-03/fr...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/frames/01-01-01-01-01-01-04/fr...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/frames/01-01-01-01-01-01-05/fr...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/working/ravdess_labels.csv\")\n\nlabel2idx = {label: idx for idx, label in enumerate(df['label'].unique())}\ndf['label_idx'] = df['label'].map(label2idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:22:44.073402Z","iopub.execute_input":"2025-07-23T18:22:44.074118Z","iopub.status.idle":"2025-07-23T18:22:44.090055Z","shell.execute_reply.started":"2025-07-23T18:22:44.074094Z","shell.execute_reply":"2025-07-23T18:22:44.089549Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(\n    df, test_size=0.2, stratify=df['label_idx'], random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:22:54.598093Z","iopub.execute_input":"2025-07-23T18:22:54.598774Z","iopub.status.idle":"2025-07-23T18:22:54.606944Z","shell.execute_reply.started":"2025-07-23T18:22:54.598750Z","shell.execute_reply":"2025-07-23T18:22:54.606358Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)  \n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:23:23.678405Z","iopub.execute_input":"2025-07-23T18:23:23.678675Z","iopub.status.idle":"2025-07-23T18:23:23.683361Z","shell.execute_reply.started":"2025-07-23T18:23:23.678653Z","shell.execute_reply":"2025-07-23T18:23:23.682657Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\n\nclass RAVDESSDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row['frame_dir']\n        image = Image.open(img_path).convert(\"RGB\")\n        label = row['label_idx']\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:23:35.513904Z","iopub.execute_input":"2025-07-23T18:23:35.514443Z","iopub.status.idle":"2025-07-23T18:23:35.519233Z","shell.execute_reply.started":"2025-07-23T18:23:35.514417Z","shell.execute_reply":"2025-07-23T18:23:35.518494Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataset = RAVDESSDataset(train_df, transform=transform)\ntest_dataset = RAVDESSDataset(test_df, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:24:01.670526Z","iopub.execute_input":"2025-07-23T18:24:01.670801Z","iopub.status.idle":"2025-07-23T18:24:01.676871Z","shell.execute_reply.started":"2025-07-23T18:24:01.670778Z","shell.execute_reply":"2025-07-23T18:24:01.676058Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_classes = len(label2idx)\n\n# Model\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel.to(device)\n\n# Class weights\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_df['label_idx']),\n    y=train_df['label_idx']\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Loss, optimizer\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:24:13.021596Z","iopub.execute_input":"2025-07-23T18:24:13.021850Z","iopub.status.idle":"2025-07-23T18:24:14.001842Z","shell.execute_reply.started":"2025-07-23T18:24:13.021831Z","shell.execute_reply":"2025-07-23T18:24:14.001280Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 208MB/s]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def evaluate(loader):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    return correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:24:20.972735Z","iopub.execute_input":"2025-07-23T18:24:20.973307Z","iopub.status.idle":"2025-07-23T18:24:20.977822Z","shell.execute_reply.started":"2025-07-23T18:24:20.973285Z","shell.execute_reply":"2025-07-23T18:24:20.977026Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import time\n\nnum_epochs = 25\n\nfor epoch in range(1, num_epochs + 1):\n    print(f\"\\nEpoch {epoch}/{num_epochs} başladı\")\n\n    \n    start_train = time.time()\n    model.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    end_train = time.time()\n\n    start_test = time.time()\n    train_acc = evaluate(train_loader)\n    test_acc = evaluate(test_loader)\n    end_test = time.time()\n\n\n    print(f\"[Epoch {epoch}] Train Accuracy: {train_acc:.4f} | Time: {end_train - start_train:.2f} sec\")\n    print(f\"[Epoch {epoch}] Test Accuracy : {test_acc:.4f} | Time: {end_test - start_test:.2f} sec\")\n\n    scheduler.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:25:40.664184Z","iopub.execute_input":"2025-07-23T18:25:40.664855Z","iopub.status.idle":"2025-07-23T18:48:55.569563Z","shell.execute_reply.started":"2025-07-23T18:25:40.664830Z","shell.execute_reply":"2025-07-23T18:48:55.568833Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/25 başladı\n[Epoch 1] Train Accuracy: 0.5373 | Time: 24.76 sec\n[Epoch 1] Test Accuracy : 0.5087 | Time: 31.37 sec\n\nEpoch 2/25 başladı\n[Epoch 2] Train Accuracy: 0.7209 | Time: 24.59 sec\n[Epoch 2] Test Accuracy : 0.6597 | Time: 30.99 sec\n\nEpoch 3/25 başladı\n[Epoch 3] Train Accuracy: 0.8225 | Time: 24.77 sec\n[Epoch 3] Test Accuracy : 0.7431 | Time: 31.21 sec\n\nEpoch 4/25 başladı\n[Epoch 4] Train Accuracy: 0.8503 | Time: 24.45 sec\n[Epoch 4] Test Accuracy : 0.7847 | Time: 31.15 sec\n\nEpoch 5/25 başladı\n[Epoch 5] Train Accuracy: 0.8941 | Time: 24.66 sec\n[Epoch 5] Test Accuracy : 0.8385 | Time: 30.96 sec\n\nEpoch 6/25 başladı\n[Epoch 6] Train Accuracy: 0.9158 | Time: 24.45 sec\n[Epoch 6] Test Accuracy : 0.8594 | Time: 31.02 sec\n\nEpoch 7/25 başladı\n[Epoch 7] Train Accuracy: 0.9327 | Time: 24.42 sec\n[Epoch 7] Test Accuracy : 0.8698 | Time: 30.88 sec\n\nEpoch 8/25 başladı\n[Epoch 8] Train Accuracy: 0.9457 | Time: 24.40 sec\n[Epoch 8] Test Accuracy : 0.8889 | Time: 31.22 sec\n\nEpoch 9/25 başladı\n[Epoch 9] Train Accuracy: 0.9497 | Time: 24.29 sec\n[Epoch 9] Test Accuracy : 0.8941 | Time: 31.22 sec\n\nEpoch 10/25 başladı\n[Epoch 10] Train Accuracy: 0.9553 | Time: 24.54 sec\n[Epoch 10] Test Accuracy : 0.8993 | Time: 31.12 sec\n\nEpoch 11/25 başladı\n[Epoch 11] Train Accuracy: 0.9622 | Time: 25.20 sec\n[Epoch 11] Test Accuracy : 0.9045 | Time: 31.65 sec\n\nEpoch 12/25 başladı\n[Epoch 12] Train Accuracy: 0.9714 | Time: 24.53 sec\n[Epoch 12] Test Accuracy : 0.8993 | Time: 31.17 sec\n\nEpoch 13/25 başladı\n[Epoch 13] Train Accuracy: 0.9683 | Time: 24.80 sec\n[Epoch 13] Test Accuracy : 0.9097 | Time: 31.74 sec\n\nEpoch 14/25 başladı\n[Epoch 14] Train Accuracy: 0.9748 | Time: 24.48 sec\n[Epoch 14] Test Accuracy : 0.9010 | Time: 31.08 sec\n\nEpoch 15/25 başladı\n[Epoch 15] Train Accuracy: 0.9701 | Time: 24.45 sec\n[Epoch 15] Test Accuracy : 0.9097 | Time: 31.13 sec\n\nEpoch 16/25 başladı\n[Epoch 16] Train Accuracy: 0.9705 | Time: 24.50 sec\n[Epoch 16] Test Accuracy : 0.9219 | Time: 31.17 sec\n\nEpoch 17/25 başladı\n[Epoch 17] Train Accuracy: 0.9753 | Time: 24.49 sec\n[Epoch 17] Test Accuracy : 0.9149 | Time: 31.04 sec\n\nEpoch 18/25 başladı\n[Epoch 18] Train Accuracy: 0.9679 | Time: 24.55 sec\n[Epoch 18] Test Accuracy : 0.9253 | Time: 30.97 sec\n\nEpoch 19/25 başladı\n[Epoch 19] Train Accuracy: 0.9709 | Time: 24.51 sec\n[Epoch 19] Test Accuracy : 0.9132 | Time: 30.87 sec\n\nEpoch 20/25 başladı\n[Epoch 20] Train Accuracy: 0.9796 | Time: 24.43 sec\n[Epoch 20] Test Accuracy : 0.9115 | Time: 31.40 sec\n\nEpoch 21/25 başladı\n[Epoch 21] Train Accuracy: 0.9748 | Time: 25.24 sec\n[Epoch 21] Test Accuracy : 0.9184 | Time: 31.60 sec\n\nEpoch 22/25 başladı\n[Epoch 22] Train Accuracy: 0.9770 | Time: 25.02 sec\n[Epoch 22] Test Accuracy : 0.9323 | Time: 31.12 sec\n\nEpoch 23/25 başladı\n[Epoch 23] Train Accuracy: 0.9753 | Time: 24.81 sec\n[Epoch 23] Test Accuracy : 0.9097 | Time: 30.84 sec\n\nEpoch 24/25 başladı\n[Epoch 24] Train Accuracy: 0.9701 | Time: 24.39 sec\n[Epoch 24] Test Accuracy : 0.9340 | Time: 31.07 sec\n\nEpoch 25/25 başladı\n[Epoch 25] Train Accuracy: 0.9813 | Time: 24.45 sec\n[Epoch 25] Test Accuracy : 0.9271 | Time: 31.73 sec\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/resnet18_ravdess.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:51:08.152165Z","iopub.execute_input":"2025-07-23T18:51:08.152420Z","iopub.status.idle":"2025-07-23T18:51:08.223544Z","shell.execute_reply.started":"2025-07-23T18:51:08.152403Z","shell.execute_reply":"2025-07-23T18:51:08.222765Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}